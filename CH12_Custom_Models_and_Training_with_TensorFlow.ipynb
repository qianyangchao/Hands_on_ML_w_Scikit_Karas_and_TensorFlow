{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0-preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0-preview is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TensorFlow like Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors and operations\n",
    "\n",
    "You can create a tensor with `tf.constant()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[1., 2., 3.], [4., 5., 6.]]) # matrix: 2x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(42) # scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like an `ndarray`, a `tf.Tensor` has a shape and a data type (dtype):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "Indexing works much like in Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 4.], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[1.],\n",
       "       [4.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([4., 5., 6.], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ops\n",
    "Most importantly, all sorts of tensor operations are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 4.],\n",
       "       [2., 5.],\n",
       "       [3., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t) # equivalant to tf.matmul( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In TensorFlow, you must write `tf.transpose(t)` since t.T is not allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(t, tf.transpose(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find all the basic math operations you need and most operations that you can find in Numpy ( e.g., `tf.reshape()`, `tf.exp()`, `tf.squeeze()`, `tf.tile()`). Some funcitons have a different name than in Numpy; for instance, `tf.reduce_mean()`, `tf.reduce_sum()`, `tf.reduce_max()`, and `tf.math.log()` are the equivalent of `np.mean()`, `np.sum()`, `np.max()`, and `np.log()`.\n",
    "\n",
    "> Many functions and classes have aliases. For example, `tf.add()` and `tf.math.add()` are the same function. This allows TensorFlow to have concise names for the most common operations while preserving well-organized packaged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `keras.backend`\n",
    "\n",
    "The Keras API has its own low-level API, located in `keras.backend`. It includes functions like `square()`, `exp()`, and `sqrt()`. In `tf.keras`, these functions generally just call the corresponding TensorFlow operations. **If you want to write code that will be portable to other Keras implementations**, you should use these keras functions, insteand of `tf.function()`s. However, they only cover a subset of all functions available in TensorFlow. FYI, `keras.backend` is commonly used as `K` for short:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[11., 26.],\n",
       "       [14., 35.],\n",
       "       [19., 46.]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "K = keras.backend\n",
    "K.square(K.transpose(t)) + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From/To NumPy\n",
    "Tensors play nice with Numpy: you can create a tensor from a NumPy array, and vice versa. You can even apply TensorFlow operations to NumPy arrays and NumPy operations to tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2., 4., 5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy() # or np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notice that NumPy uses 64-bit precision by default, while TensorFlow uses 32-bit. This is because 32-bit precision is generally more than enough for neural networks, plus it runs faster and uses less RAM. So, when you create a tensor from a numpy array, **make sure to set `dtype=tf.float32`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conflicting Types\n",
    "Type conversions can significantly hurt performance, and they can easily go unnoticed when they are done automatically. To avoid this, **TensorFlow does not perform any type conversions automatically: it just raises an exception if you try to execute an operation on tensors with incompatible types**. For example, you cannot add a float tensor and an integer tensor, and you cannot even add a 32-bit float and a 64-bit float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40., dtype=tf.float64)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tf.constant(40., dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "\n",
    "The `tf.Tensor` values we've seen so far are immutable: you cannot modify them. This means that we cannot use regular tensors to implement weights in a neural network, since they need to be tweaked by backpropagation. Plus, other parameters may also need to change over time(e.g., a moment optimizer keeps trak of past gradients). What we need is a `tf.Variable`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `tf.Variable` acts much like a `tf.Tensor`: you can perform the same operations with it, it plays nicely with NumPy as well, and it is just as picky with types. But __it can also be modified__ in place using the `assign()` method (or `assign_add()` or `assign_sub()`, which increment or decrement the variable by the given value). You can also modify individual cells (or slices), by using the cell's (or slice's) `assign()` method(direct assignment will not work) or by using the `scatter_update()` or `scatter_nd_update()` methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2*v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 1].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, 2].assign([0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update([[0,0], [1, 2]], updates=[100., 200.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In practice you will raely have to create variables manually, since Keras provides an `add_weight()` method that will take care of it for you, as we will see. Moreover, model parameters will generally be updated directly by the optimzers, so you will rarely need to update variables manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String tensors\n",
    "Are regular tensors of type tf.string. These represent byte strings, not Unicode strings, so if you create a string tensor using a Unicode string (e.g., a regular Python 3 string like \"café\"), then it will get encoded to UTF-8 automatically (e.g., b\"caf\\xc3\\xa9\"). Alternatively, you can represent Unicode strings using tensors of type tf.int32, where each item represents a Unicode code point (e.g., [99, 97, 102, 233]). The tf.strings package (with an s) contains ops for byte strings and Unicode strings (and to convert one into the other). It’s important to note that a tf.string is atomic, meaning that its length does not appear in the tensor’s shape. Once you convert it to a Unicode tensor (i.e., a tensor of type tf.int32 holding Unicode code points), the length appears in the shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'hello world'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(b\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'hello world'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'caf\\xc3\\xa9'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(\"café\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233], dtype=int32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = tf.constant([ord(c) for c in \"café\"])\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.strings.unicode_encode(u, \"UTF-8\")\n",
    "tf.strings.length(b, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233], dtype=int32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(b, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tf.constant([\"Café\", \"Coffee\", \"caffè\", \"咖啡\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([4, 6, 5, 2], dtype=int32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.length(p, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232], [21654, 21857]]>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = tf.strings.unicode_decode(p, \"UTF8\")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232], [21654, 21857]]>\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ragged tensors (tf.RaggedTensor)\n",
    "Represent static lists of lists of tensors, where every tensor has the same shape and data type. The tf.ragged package contains operations for ragged tensors. A ragged tensor is a special kind of tensor that represents a list of arrays of different sizes. More generally, it is a tensor with one or more *ragged dimensions*, meaning dimensions whose slices may have different lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 67 111 102 102 101 101], shape=(6,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232]]>\n"
     ]
    }
   ],
   "source": [
    "print(r[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[65, 66], [], [67]]>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = tf.ragged.constant([[65, 66], [], [67]])\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232], [21654, 21857], [65, 66], [], [67]]>\n"
     ]
    }
   ],
   "source": [
    "print(tf.concat([r, r2], axis=0)) # along the axis 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233, 68, 69, 70], [67, 111, 102, 102, 101, 101, 71], [99, 97, 102, 102, 232], [21654, 21857, 72, 73]]>\n"
     ]
    }
   ],
   "source": [
    "r3 = tf.ragged.constant([[68, 69, 70], [71], [], [72, 73]])\n",
    "print(tf.concat([r, r3], axis=1)) # along the axis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=array([b'DEF', b'G', b'', b'HI'], dtype=object)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(r3, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you call the `to_tensor()` method, it gets converted to a regular tensor, padding shorter tensors with *zeros* to get tensors of equal lengths (you can change the default value by setting the `default_value` argument):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6), dtype=int32, numpy=\n",
       "array([[   67,    97,   102,   233,     0,     0],\n",
       "       [   67,   111,   102,   102,   101,   101],\n",
       "       [   99,    97,   102,   102,   232,     0],\n",
       "       [21654, 21857,     0,     0,     0,     0]], dtype=int32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.to_tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse tensors (tf.SparseTensor)\n",
    "TensorFlow can also efficiently represent *sparse tensors* (i.e., tensors containing mostly zeros). Just create a `tf.SparseTensor`, specifying the indices and values of the nonzero elements and the tensor's shape. The indices must be listed in \"reading order\" (from left to right, and top to bottom). If you are unsure, just use `tf.sparse.reorder()`. You can convert a sparse tensor to a dense tensor using `tf.sparse.to_dense()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.SparseTensor(indices=[[0, 1], [1, 0], [2, 3]],\n",
    "                    values=[1., 2., 3.],\n",
    "                    dense_shape=[3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [0., 0., 0., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = s * 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupported operand type(s) for +: 'SparseTensor' and 'float'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    s3 = s + 1.\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 30.,  40.],\n",
       "       [ 20.,  40.],\n",
       "       [210., 240.]], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4 = tf.constant([[10., 20.], [30., 40.], [50., 60.], [70., 80.]])\n",
    "tf.sparse.sparse_dense_matmul(s, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 2]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([1. 2.], shape=(2,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "s5 = tf.SparseTensor(indices=[[0, 2], [0, 1]],\n",
    "                     values=[1., 2.],\n",
    "                     dense_shape=[3, 4])\n",
    "print(s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices[1] = [0,1] is out of order. Many sparse ops require sorted indices.\n",
      "    Use `tf.sparse.reorder` to create a correctly ordered copy.\n",
      "\n",
      " [Op:SparseToDense]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.sparse.to_dense(s5)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 2., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s6 = tf.sparse.reorder(s5) # reorder index-value pairs\n",
    "tf.sparse.to_dense(s6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sets\n",
    "Are represented as regular tensors (or sparse tensors). For example, tf.constant([[1, 2], [3, 4]]) represents the two sets {1, 2} and {3, 4}. TensorFlow supports sets of integers or strings (but not floats). It represents them using regular tensors. For example, the set {1, 5, 9} is just represented as the tensor[[1, 5, 9]]. Note that the tensor must have at least two dimensions, and the sets must be in the last dimension. You can manipulate sets using operations from the `tf.sets` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7feec4b83a50>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1 = tf.constant([[2, 3, 5, 7], [7, 9, 0, 0]])\n",
    "set2 = tf.constant([[4, 5, 6], [9, 10, 0]])\n",
    "tf.sets.union(set1, set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
       "array([[ 2,  3,  4,  5,  6,  7],\n",
       "       [ 0,  7,  9, 10,  0,  0]], dtype=int32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(tf.sets.union(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[2, 3, 7],\n",
       "       [7, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(tf.sets.difference(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[5, 0],\n",
       "       [0, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(tf.sets.intersection(set1, set2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Arrays (tf.TensorArray)\n",
    "\n",
    "A `tf.TensorArray` represents a list of tensors. This can be handy in dynamic models containing loops, to accumulate results and later compute some statistics. You can read or write tensors at any location in any array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
    "array = array.write(0, tf.constant([1., 2.]))\n",
    "array = array.write(1, tf.constant([3., 10.]))\n",
    "array = array.write(2, tf.constant([5., 7.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 3., 10.], dtype=float32)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.read(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notice that reading an item pops it from the array, replacing it with a tensor of the same shape, full of zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating a `TensorArray`, you must provide its **size**, except in graph mode. Alternatively, you can leave the size unset and instead set `dynamic_size=True`, but this will hinder performance, so if you know the `size` in advance, you should set it. You must also specify the `dtype`, and all elements must have the same shape as the first one written to the array.\n",
    "\n",
    "You can stack all the items into a regular tensor by calling the `stack()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [5., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 3.], dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, variance = tf.nn.moments(array.stack(), axes=0)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([4.6666665, 8.666667 ], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading and preparing the California housing dataset. We first load it, then split it into a training set, a validation set and a test set, and finally we scale it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss  = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For better performance, you should use a vectorized implementation, as in this example. Moreover, if you want to benefit from TensorFlow’s graph features, you should use only TensorFlow operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 3.5))\n",
    "z = np.linspace(-4, 4, 200)\n",
    "\n",
    "plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
    "plt.plot(z, z**2 / 2, \"b:\", linewidth=1, label=r\"$\\frac{1}{2}z^2$\")\n",
    "\n",
    "plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"r--\")\n",
    "plt.plot([1, 1], [0, huber_fn(0., 1.)], \"r--\")\n",
    "plt.gca().axhline(y=0, color='k')\n",
    "plt.gca().axvline(x=0, color='k')\n",
    "plt.axis([-4, 4, 0, 4])\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Huber loss\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5351 - mae: 0.8864 - val_loss: 0.1999 - val_mae: 0.4904\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2100 - mae: 0.5055 - val_loss: 0.2040 - val_mae: 0.4903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feeb0bb5810>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet! But what happens to this custom loss when you save the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving/Loading Models with Custom Objects\n",
    "\n",
    "Saving a model containing a custom loss function works fine, as Keras saves the name of the function. Whenver you load it, you will need to provide a dictionary that maps the function name to the actual function. More generally, when you load a model containing custom objects, you nneed to map the names to the objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss.h5\",\n",
    "                                custom_objects={\"huber_fn\": huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2023 - mean_absolute_error: 0.4943 - val_loss: 0.2010 - val_mean_absolute_error: 0.4863\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1989 - mean_absolute_error: 0.4891 - val_loss: 0.2094 - val_mean_absolute_error: 0.4931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feea12b76d0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the current implementation, any error between -1 and 1 is considered \"small\". But what if you want a different threshold? One solution is to create a function that creates a configures loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = threshold * (tf.abs(error) - threshold / 2)\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2207 - mae: 0.4880 - val_loss: 0.2166 - val_mae: 0.4726\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2157 - mae: 0.4825 - val_loss: 0.2586 - val_mae: 0.4958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feed0ea17d0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, when you save the model, the `threshold` will not be saved. This means that you will have to specify the `threshold` value when loading the model (note that the name to use is \"`huber_fn`\", which is the name of the function you gave Keras, not the name of the function that created it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_threshold_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_threshold_2.h5\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0)}) # not create_huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2129 - mean_absolute_error: 0.4778 - val_loss: 0.2231 - val_mean_absolute_error: 0.4722\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2096 - mean_absolute_error: 0.4739 - val_loss: 0.2380 - val_mean_absolute_error: 0.4748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feeb0cd4b90>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can solve this by creating a subclass of the `keras.losses.Loss` class, and then implementing its `get_config()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = self.threshold * (tf.abs(error) - self.threshold / 2)\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6796 - mae: 0.8583 - val_loss: 0.3403 - val_mae: 0.5609\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2450 - mae: 0.5168 - val_loss: 0.2500 - val_mae: 0.4998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feeb0d72650>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_class.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\", \n",
    "                               custom_objects={\"HuberLoss\": HuberLoss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2300 - mean_absolute_error: 0.5012 - val_loss: 0.2376 - val_mean_absolute_error: 0.4877\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2247 - mean_absolute_error: 0.4927 - val_loss: 0.2136 - val_mean_absolute_error: 0.4750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feeb0db2790>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\", \n",
    "                               custom_objects={\"HuberLoss\": HuberLoss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z): # return value is just tf.nn.softplus(z)\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "def my_positive_weights(weights): # return value is just tf.nn.relu(weights)\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(1, activation=my_softplus,\n",
    "                           kernel_initializer=my_glorot_initializer,\n",
    "                           kernel_regularizer=my_l1_regularizer,\n",
    "                           kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=my_l1_regularizer,\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.5542 - mae: 0.8962 - val_loss: 1.4154 - val_mae: 0.5607\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5943 - mae: 0.5256 - val_loss: 1.4399 - val_mae: 0.5137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feec4e050d0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"my_l1_regularizer\": my_l1_regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=MyL1Regularizer(0.01),\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.5901 - mae: 0.8871 - val_loss: 1.4671 - val_mae: 0.5719\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6168 - mae: 0.5327 - val_loss: 1.3017 - val_mae: 0.5177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feeb0c83e50>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"MyL1Regularizer\": MyL1Regularizer(0.01),\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 0s 882us/step - loss: 2.4099 - huber_fn: 0.8630\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 828us/step - loss: 0.7635 - huber_fn: 0.2597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feeb0e60510>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Warning**: if you use the same function as the loss and a metric, you may be surprised to see different results. This is generally just due to floating point precision errors: even though the mathematical equations are equivalent, the operations are not run in the same order, which can lead to small differences. Moreover, when using sample weights, there's more than just precision errors:\n",
    "* the loss since the start of the epoch is the mean of all batch losses seen so far. Each batch loss is the sum of the weighted instance losses divided by the _batch size_ (not the sum of weights, so the batch loss is _not_ the weighted mean of the losses).\n",
    "* the metric since the start of the epoch is equal to the sum of weighted instance losses divided by sum of all weights seen so far. In other words, it is the weighted mean of all the instance losses. Not the same thing.\n",
    "\n",
    "If you do the math, you will find that loss = metric * mean of sample weights (plus some floating point precision error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 0s 876us/step - loss: 0.1189 - huber_fn: 0.2413\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 877us/step - loss: 0.1132 - huber_fn: 0.2297\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11888086050748825, 0.11972719750271266)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history[\"loss\"][0], history.history[\"huber_fn\"][0] * sample_weight.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming metrics\n",
    "\n",
    "For each batch during training, Keras will compute this metric and keep track of its mean since the beginning of the epoch. Most of the time, this is exactly what you wannt. But not always! Consider a binary classifier's precision, for example, precesion is the number of true positives divided by the number of positive predictions (including both true positives and false positives). Suppose the model made five positive predictions in the first batch, four of which were correct: that's 80% precision. Then suppose the model made three positive predictions in the second batch, but they were all incorect: that's 0% precision for the second batch. If you just compute the mean of these two precisions, you get 40%. But wait a second - that's not  the model's precision over these two batches! Indeed, there were a total of four true positives (4 + 0) out of eight positive predictions(5 + 3), so the overall precision is 50%, not 40%. What we need is an object that can keep track of the number of true positives and the number of false positives and that can compute their ratio when requested. This is what the `keras.metrics.Precision` class does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_true, y_pred\n",
    "precision = keras.metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1],  \n",
    "          [1, 1, 0, 1, 0, 1, 0, 1]) # 4 / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0, 1, 0, 0, 1, 0, 1, 1], \n",
    "          [1, 0, 1, 1, 0, 0, 0, 0]) # (4 + 0) / (5 + 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we created a `Precision` object, then we used it like a function, passing it the labels and predictions for the first batch, then for the second batch (note that we could also have passed sample weights). We used the same number of true and false positives as in the example we just discussed. After the first batch, it returns a precision of 80%; then after the second batch, it returns 50% (which is the overall precision so far, not the second batch's precision). This is called a **streaming metric** (or **stateful metric**), as it is gradually updated, batch after batch. At any point, we can call the `result()` method to get the current value of the metric. We can also look at its variables (tracking the number of true and false positives) by using the `variables` attribute, and we can reset these variables using the `reset_states()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a streaming metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs) # handles base args (e.g., dtype)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # to keep track of running metric during each EPOCH, \n",
    "        # not to average means of all batches  \n",
    "        metric = self.huber_fn(tf.cast(y_true, tf.float32), y_pred) # be careful with dtype\n",
    "        self.total.assign_add(tf.reduce_sum(metric))  ##\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32)) ##\n",
    "    def result(self):\n",
    "        # result after update_state\n",
    "        return self.total / self.count\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=14.0>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = HuberMetric(2.)\n",
    "\n",
    "# total = 2 * |10 - 2| - 2²/2 = 14\n",
    "# count = 1\n",
    "# result = 14 / 1 = 14\n",
    "\n",
    "m(tf.constant([[2.]]), tf.constant([[10.]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total = total + (|1 - 0|² / 2) + (2 * |9.25 - 5| - 2² / 2) = 14 + 7 = 21\n",
    "# count = count + 2 = 3\n",
    "# result = total / count = 21 / 3 = 7\n",
    "m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))\n",
    "\n",
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=21.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=3.0>]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=0.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=0.0>]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.reset_states()\n",
    "m.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the `HuberMetric` class works well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7858 - huber_metric_1: 0.7858\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2372 - huber_metric_1: 0.2372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feea12058d0>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_metric.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.create_huber.<locals>.huber_fn(y_true, y_pred)>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_metric.h5\",\n",
    "                               custom_objects={\"huber_fn\": create_huber(2.0),\n",
    "                                               \"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2277 - huber_metric_1: 0.2277\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2215 - huber_metric_1: 0.2215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fee80aefa50>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.create_huber.<locals>.huber_fn(y_true, y_pred)>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'huber_metric_1']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.metrics.Mean at 0x7feea1576d90>,\n",
       " <__main__.HuberMetric at 0x7feea1576890>]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[-1].threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it works fine! More simply, we could have created the class like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Mean): # this time mean is super()\n",
    "    def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        super().__init__(name=name, dtype=dtype)\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(tf.cast(y_true, tf.float32), y_pred)\n",
    "        super().update_state(metric, sample_weight)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class handles shapes better, and it also supports sample weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.Huber(2.0), optimizer=\"nadam\", weighted_metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 0s 932us/step - loss: 0.5085 - HuberMetric: 1.0043\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 890us/step - loss: 0.1359 - HuberMetric: 0.2684\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5085268616676331, 0.5085270355341701)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history[\"loss\"][0], history.history[\"HuberMetric\"][0] * sample_weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_metric_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_metric_v2.h5\",        \n",
    "                               custom_objects={\"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 0s 892us/step - loss: 0.2363 - HuberMetric: 0.2363\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 919us/step - loss: 0.2240 - HuberMetric: 0.2240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fee80c769d0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[-1].threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.metrics.Mean at 0x7fee80c26850>,\n",
       " <__main__.HuberMetric at 0x7fee80c26150>]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layers\n",
    "You may occasionally want to build an architecture that contains an exotic layer for which TensorFlow does not provide a default implementation. In this case, you will need to create a custom layer. Or you may simply want to build a very repetitive architecture, containing identical blocks of layers repeated many times, and it would be convenient to treat each block of layers as a single layer. For example, if the model is a sequence of layers A, B, C, A, B, C, A, B, C, then you might want to define a custom layer D containing layers A, B, C, so your model would then simply be D, D, D. Let's see how to build custom layers.\n",
    "First, some layers have no weights, such as `keras.layers.Flatten` or `keras.layers.ReLU`. If you want to create a custom layer without any weights, the simplest option is to write a function and wrap it in a `keras.layers.Lambda` layer. For example, the following layer will apply the exponential function to its inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponential_layer([-1., 0., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an exponential layer at the output of a regression model can be useful if the values to predict are positive and with very different scales (e.g., 0.001, 10., 10000):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "162/162 - 0s - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "    exponential_layer\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=5,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This custom layer can be used like any other layer, using the Sequential API, the Functional API, or the Subclassing API. You can also use it as an activation function (or you could use `activation=tf.exp`, `activation=keras.activation.exponential`, or simply `activation=\"exponential\"`). The exponential layer is sometimes used in the output layer of a regression model when the values to predict have very different scales(e.g., 0.001, 10., 1,000.). \n",
    "\n",
    "To build a custom stateful layer (i.e., a layer with weights), you need to create a subclass of the `keras.layers.Layer` class. For example, the following class implements a simplified version of the `Dense` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units,\n",
    "                \"activation\": keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    MyDense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    MyDense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.9191 - val_loss: 0.8107\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6184 - val_loss: 0.5070\n",
      "162/162 - 0s - loss: 0.5466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5466161966323853"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_layer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_layer.h5\",\n",
    "                                custom_objects={\"MyDense\": MyDense})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a layer with jultiple inputs (e.g., Concatenate), the argument to the `call()` method should be a tuple containing all the inputs, and similarly the argument to the `compute_output_shape()` method should be a tuple containing each input's batch shape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        return X1 + X2, X1 * X2\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1 = keras.layers.Input(shape=[2])\n",
    "inputs2 = keras.layers.Input(shape=[2])\n",
    "outputs1, outputs2 = MyMultiLayer()((inputs1, inputs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your layer needs to have a different behavior during training and during testing (e.g., if it uses `Dropout` or `BatchNormalization` layers), then you must add a `training` argument to the `call()` method and use this argument to decide what to do. For example, let's create a layer that adds Guassian noise during training (for regularization) and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4792 - val_loss: 0.4898\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4180 - val_loss: 0.5392\n",
      "162/162 - 0s - loss: 0.4064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40644848346710205"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Models\n",
    "\n",
    "#### `<Residual Block>`\n",
    "<img src=\"https://github.com/soo-pecialist/Hands_on_ML_w_Scikit_Karas_and_TensorFlow/blob/master/images_used/figure12_3.jpg?raw=true\" alt=\"Figure 12-3\" width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_scaled = X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_layers = n_layers                                     \n",
    "        self.n_neurons = n_neurons                                   \n",
    "        self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "                       for _ in range(n_layers)]\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z\n",
    "    \n",
    "    def get_config(self):                                            \n",
    "        base_config = super().get_config()                           \n",
    "        return {**base_config,                                       \n",
    "                \"n_layers\": self.n_layers, \"n_neurons\": self.n_neurons}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.output_dim = output_dim                               \n",
    "        self.hidden1 = keras.layers.Dense(30, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\", \n",
    "                                          input_shape=(8,))\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)\n",
    "\n",
    "    def get_config(self):                                            \n",
    "        base_config = super().get_config()                           \n",
    "        return {**base_config,                                       \n",
    "                \"output_dim\": self.output_dim}                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 4.9429\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.9165\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9065\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7863\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8666\n",
      "162/162 - 0s - loss: 1.1753\n"
     ]
    }
   ],
   "source": [
    "model = ResidualRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "y_pred = model.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"residual_regressor\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              multiple                  270       \n",
      "_________________________________________________________________\n",
      "residual_block (ResidualBloc multiple                  1860      \n",
      "_________________________________________________________________\n",
      "residual_block_1 (ResidualBl multiple                  1860      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  31        \n",
      "=================================================================\n",
      "Total params: 4,021\n",
      "Trainable params: 4,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/soohyeonkim/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: my_custom_model.ckpt/assets\n"
     ]
    }
   ],
   "source": [
    "#### SAVE\n",
    "model.save(\"my_custom_model.ckpt\")\n",
    "#### LOAD\n",
    "model = keras.models.load_model(\"my_custom_model.ckpt\",\n",
    "                               custom_objects={\n",
    "                                   \"ResidualBlock\": ResidualBlock,\n",
    "                                   \"ResidualRegressor\": ResidualRegressor\n",
    "                               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"residual_regressor\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              multiple                  270       \n",
      "_________________________________________________________________\n",
      "residual_block (ResidualBloc multiple                  1860      \n",
      "_________________________________________________________________\n",
      "residual_block_1 (ResidualBl multiple                  1860      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  31        \n",
      "=================================================================\n",
      "Total params: 4,021\n",
      "Trainable params: 4,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We could have defined the model using the sequential API instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "block1 = ResidualBlock(2, 30)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", \n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       input_shape=(8,)),\n",
    "    block1, block1, block1, block1,\n",
    "    ResidualBlock(2, 30),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 4.4256\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1576\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5773\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7339\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9751\n",
      "162/162 - 0s - loss: 1.1142\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "y_pred = model.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "residual_block_2 (ResidualBl (None, 30)                1860      \n",
      "_________________________________________________________________\n",
      "residual_block_3 (ResidualBl (None, 30)                1860      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 4,021\n",
      "Trainable params: 4,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"custom_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses and Metrics Based on Model Internals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: check https://github.com/tensorflow/tensorflow/issues/26260\n",
    "```python\n",
    "class ReconstructingRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        \"\"\" The constructor creates the DNN with five dense hidden \n",
    "            layers and one dense output layer.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation=\"selu\",\n",
    "                                          kernel_initializer=\"lecun_normal\")\n",
    "                       for _ in range(5)]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "#         self.reconstruction_mean = keras.metrics.Mean(name=\"reconstruction_error\")\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        \"\"\" The build() method creates an extra dense layer which will\n",
    "            be used to reconstruct the inputs of the model. It must be\n",
    "            created here because its number of units must be equal to \n",
    "            the number of inputs, and its number is unknown before the \n",
    "            build() method is called\"\"\"\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "        super().build(batch_input_shape)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"The call() method processes the inputs through all five hidden layers, \n",
    "        then passes the result through the reconstruction layer, which produces \n",
    "        the reconstruction.\n",
    "        \n",
    "        Then the call() method computes the reconstruction loss (the mean squared \n",
    "        difference between the reconstruction and the inputs), and adds it to the \n",
    "        model’s list of losses using the add_loss() method. Notice that we scale \n",
    "        down the reconstruction loss by multiplying it by 0.05 (this is a\n",
    "        hyperparameter you can tune). This ensures that the reconstruction loss does \n",
    "        not dominate the main loss.\n",
    "        \n",
    "        Finally, the call() method passes the output of the hidden layers to the \n",
    "        output layer and returns its output.\"\"\"\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(lambda: 0.05 * recon_loss)\n",
    "#         if training:\n",
    "#             result = self.reconstruction_mean(recon_loss)\n",
    "#             self.add_metric(result)\n",
    "        return self.out(Z)\n",
    "\n",
    "model = ReconstructingRegressor(1)\n",
    "model.build(tf.TensorShape([None, 8]))       # <= Fails if this line is removed\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\", experimental_run_tf_function=False)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom losses and metrics we defined earlier were all based on the labels and the predictions (and optionally sample weights). There will be times when you want to define losses based on other parts of your model, such as the weights or activations of its hidden layers. This may be useful for regularization purposes or to monitor some internal aspect of your model. To define a custom loss based on model internals, compute it based on any part of the model you want, then pass the result to the `add_loss()` method.\n",
    "\n",
    "For example, let’s build a custom regression MLP model composed of a stack of five hidden layers plus an output layer. This custom model will also have an auxiliary output on top of the upper hidden layer. The loss associated to this auxiliary output will be called the reconstruction loss: it is the mean squared difference between the reconstruction and the inputs. By adding this reconstruction loss to the main loss, __we will encourage the model to preserve as much information as possible through the hidden layers—even information that is not directly useful for the regression task itself__. In practice, this loss sometimes improves generalization (it is a regularization loss). Here is the code for this custom model with a custom reconstruction loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ReconstructingRegressor(keras.models.Model):\n",
    "#     def __init__(self, output_dim, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.hidden = [keras.layers.Dense(30, activation=\"selu\",\n",
    "#                                           kernel_initializer=\"lecun_normal\")\n",
    "#                        for _ in range(5)]\n",
    "#         self.out = keras.layers.Dense(output_dim)\n",
    "#         # TODO: check https://github.com/tensorflow/tensorflow/issues/26260\n",
    "#         #self.reconstruction_mean = keras.metrics.Mean(name=\"reconstruction_error\")\n",
    "\n",
    "#     def build(self, batch_input_shape):\n",
    "#         n_inputs = batch_input_shape[-1]\n",
    "#         self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "#         super().build(batch_input_shape)\n",
    "    \n",
    "#     @tf.function\n",
    "#     def call(self, inputs, training=None):\n",
    "#         Z = inputs\n",
    "#         for layer in self.hidden:\n",
    "#             Z = layer(Z)\n",
    "#         reconstruction = self.reconstruct(Z)\n",
    "#         recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "#         self.add_loss(lambda: 0.05 * recon_loss)\n",
    "#         #if training:\n",
    "#         #    result = self.reconstruction_mean(recon_loss)\n",
    "#         #    self.add_metric(result)\n",
    "#         return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ReconstructingRegressor(1)\n",
    "# model.build(tf.TensorShape([None, 8])) # TODO: check https://github.com/tensorflow/tensorflow/issues/26274\n",
    "# model.compile(loss=\"mse\", optimizer=\"nadam\", experimental_run_tf_function=False)\n",
    "# history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "# y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Gradients Using Autodiff\n",
    "\n",
    "#### `<Reverse-mode autodiff>`\n",
    "<img src=\"https://github.com/soo-pecialist/Hands_on_ML_w_Scikit_Karas_and_TensorFlow/blob/master/images_used/FigureD_3.png?raw=true\" alt=\"Figure 12-3\" width=800>\n",
    "\n",
    "**Reverse-mode autodiff** is the solutino implemented by TensorFlow. It **first goest through the graph in the forward direction to compute the value of each node**. Then it does a **second pass, this time in the reverse direction, to compute all the partial derivatives**. The name \"reverse mode\" comes from this second pass through the graph, where gradients flow in the reverse direction. The above figure represents the second pass. During the first pass, *all the node values are computed*. Given function is $f(x, y) = x^2y + y + 2$. The idea is to gradually go down the graph, computing the partial derivative of $f(x, y)$ with regard to each consecutive node, until we reach the variable nodes. For this, reverse-mode autodiff relies heavily on the *chain rule*. \n",
    "\n",
    "Reverse-mode autodiff is very powerful and accurate technique, especially when there are many inputs and few outputs, since it requires **only one forward pass plus one reverse pass per output to compute all the partial derivatives for all outputs with regard to all inputs**. In the figure above, the numerical resutls are computed on the fly, at each node. However, that's not exactly what TensorFlow does: instead, it creates a new computational graph. In order words, it implements *symbolic* reverse-mode autodiff. This way the computational graph to compute the gradients of the loss with regard to all the parameters in the neural network **only needs to be generated once$$, and then it can be executed over and over again, whenever the optimizer needs to compute the gradients. Moreover, this makes it possible to compute higher-order derivatives if needed. \n",
    "\n",
    "---\n",
    "\n",
    "To understand how to use autodiff to compute gradients automatically, let's consider a simple toy function:\n",
    "\n",
    "$ f(w_1, w_2) = 3w_1^2 + 2w_1w_2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + 2 * w1 * w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial}{\\partial w_1}f(w_1, w_2)|_{w_1 = 5, w_2 = 3}$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.000003007075065"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2 = 5, 3\n",
    "eps = 1e-6\n",
    "(f(w1 + eps, w2) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial}{\\partial w_2}f(w_1, w_2)|_{w_1 = 5, w_2 = 3}$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000003174137"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(w1, w2 + eps) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks about right! this works rather well and is easy to implement, but it is just an approximation, and importantly you need to call `f()` at least once per parameter. Needing to call `f()` at least once per parameter makes this approach intractable for large neural networks. So instead, we should use autodiff. TensorFlow Makes this pretty simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define two variables $w_1$ and $w_2$, then we create `tf.GradientTape` context that will automatically record every operation that involves a variable, and finally we ask this tape to compute the gradients of the result $z$ with regard to both variable $[w_1, w_2]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tape is automatically erased immediately after you call its `gradient()` method, so you will get an exception if you try to call `gradient()` twice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientTape.gradient can only be called once on non-persistent tapes.\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "try:\n",
    "    dz_dw2 = tape.gradient(z, w2)\n",
    "except RuntimeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=36.0>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dw1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to call `gradient()` more than once, you must take the tape **persistent** and delete each time you are done with it to free resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "dz_dw2 = tape.gradient(z, w2) # works now!\n",
    "del tape # don't forget to delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dw1, dz_dw2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the tape will only track operations involving variables, so if you try to compute the gradient of `z` with regard to anything other than a variable, the result will be `None`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you can force the tape to **watch** any tensors you like, to record every operation that involves them. You can then compute gradients with regard to these tensors, as if they were variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1) # force watch\n",
    "    tape.watch(c2) # force watch\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time a gradient tape is used to comptue the gradients of a single value (usually the loss) with regard to a set of vectors (usually the model parameters). This is where reverse-mode autodiff shines, as it just needs to do one forward pass and one reverse pass to get all the gradients at once. If you try to compute the gradients of a vector, for example a vector containing multiple losses, then TensorFlow will **compute the gradients of the vector's sum**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "tape.gradient([z1, z2, z3], [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([136.  30.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "print(tf.reduce_sum(tf.stack([tape.gradient(z, [w1, w2]) for z in (z1, z2, z3)]), axis=0))\n",
    "del tape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ever need to get the individual gradients (e.g., the gradients of each loss with regard to the model parameters), you must call the tape's `jacobian()` method: it will perform reverse-mode autodiff once for each loss in the vector (all in parallel by default). It is even possible to compute *second-order* partial derivatives (the `Hessians`, i.e., the partial derivatives of the partial derivatives). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f(w_1, w_2) = 3&w_1^2 + 2w_1w_2  \\\\\n",
    "\\frac{\\partial{f}}{\\partial{w_1}} = 6w_1 + 2w_2 & \\qquad \n",
    "\\frac{\\partial{f}}{\\partial{w_2}} = 2w_1 \\\\ \n",
    "\\\\\n",
    "\\frac{\\partial^{2}{f}}{\\partial{w_1}\\partial{w_1}} = 6 & \\qquad \n",
    "\\frac{\\partial^{2}{f}}{\\partial{w_1}\\partial{w_2}} = 2 \\\\\n",
    "\\frac{\\partial^{2}{f}}{\\partial{w_2}\\partial{w_1}} = 2 & \\qquad \n",
    "\\frac{\\partial^{2}{f}}{\\partial{w_2}\\partial{w_2}} = 0 \n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as hessian_tape:\n",
    "    with tf.GradientTape() as jacobian_tape: # jacobian()\n",
    "        z = f(w1, w2)\n",
    "    jacobians = jacobian_tape.gradient(z, [w1, w2])\n",
    "    \n",
    "hessians = [hessian_tape.gradient(jacobian, [w1, w2])\n",
    "            for jacobian in jacobians]\n",
    "\n",
    "del hessian_tape\n",
    "del jacobian_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=2.0>, None]]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases you may want to stop gradients from backpropagating through some part of your neural network. To do this, you must use the `tf.stop_gradient()` function. The function returns its inputs during the forward pass (like `tf.identity()`), but it does not let gradients through during backpropagation (it acts like a constant):\n",
    "\n",
    "\n",
    "$ f(w_1, w_2) = 3w_1^2 + c(2w_1w_2) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you may occasionally run into some numerical issues when computing gradients. For example, if you compute the gradients of `my_softplus()` function for large inputs, the result will be `NaN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=nan>]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## recall\n",
    "\"\"\"\n",
    "def my_softplus(z): \n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\"\"\"\n",
    "\n",
    "x = tf.Variable(100.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=30.0>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.log(tf.exp(tf.constant(30., dtype=tf.float32)) + 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([30.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because computing the gradients of this function using autodiff leads to some numerical difficulties: due to **floating-point precision errors**, autodiff ends up computing infinity divided by infinity (which returns NaN). Fortunately, we can analytically find that the derivative of the softplus function is just $1/(1+1/\\exp{(x)})$, which is numerically stable. \n",
    "\n",
    "We can tell TensorFlow to use this stable function when computing the gradients of `my_softplus()` function by decorating it with `@tf.custom_gradient` and making it **return both its normal output and the function that computes the derivatives**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient \n",
    "def my_better_softplus(z):\n",
    "    exp = tf.exp(z)\n",
    "    def my_softplus_gradients(grad): # receive the gradients that were backpropagated so far\n",
    "        return grad / (1 + 1 / exp) # multiply them with this function's gradients due to chain rule\n",
    "    return tf.math.log(exp + 1), my_softplus_gradients # return normal output & derivative function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=40.0>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_better_softplus(tf.constant(40., dtype=tf.float32)) # returns normal output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(100.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_better_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=inf>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_better_softplus(tf.constant(100., dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now get the proper result, even for larger input values (however, the main output still explodes because of the exponential; one workaround is to use `tf.where()` to return the inputs where they are large)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_better_softplus(z):\n",
    "    return tf.where(z > 30., z, tf.math.log(tf.exp(z) + 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1000.], dtype=float32)>,\n",
       " [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([1000.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_better_softplus(x)\n",
    "\n",
    "z, tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Gradients Using Autodiff\n",
    "## Custom Training Loops\n",
    "\n",
    "In some rare cases, the `fit()` method may not be flexible enough for what you need to do. You may also like to write custom training loops simply to feel more confident that they do precisely what you intend them to do. It  can sometimes feel safer to make everything explicit. However, remember that writing a custom training loop will make your code longer, more error-prone, and harder to maintain.\n",
    "> Unless you really need the extra flexibility, you should preper `fit()` method rather than implementing your own training loop, especially if you work in a team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's build a simple model. No need to compile it, since we will handle theh training loop manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = keras.regularizers.l2(0.05)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=l2_reg),\n",
    "    keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create a tiny function that will randomly sample a batch of instances from the trainning set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also define a function that will display the training status, including the number of steps, the total number of steps, the mean loss since the starrt of the epoc, and other metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{}/{} - \".format(iteration, total) + metrics,\n",
    "          end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fancier version with a progress bar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_bar(iteration, total, size=30):\n",
    "    running = iteration < total\n",
    "    c = \">\" if running else \"=\"\n",
    "    p = (size - 1) * iteration // total\n",
    "    fmt = \"{{:-{}d}}/{{}} [{{}}]\".format(len(str(total)))\n",
    "    params = [iteration, total, \"=\" * p + c + \".\" * (size - p - 1)]\n",
    "    return fmt.format(*params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 3500/10000 [=>....]'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "progress_bar(3500, 10000, size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{} - {}\".format(progress_bar(iteration, total), metrics), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "source": [
    "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "metrics = [keras.metrics.MeanAbsoluteError(name=\"mae\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "11610/11610 [==============================] - loss: 1.3955 - mae: 0.5722\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - loss: 0.6774 - mae: 0.5280\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - loss: 0.6351 - mae: 0.5177\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - loss: 0.6384 - mae: 0.5181\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - loss: 0.6440 - mae: 0.5222\n"
     ]
    }
   ],
   "source": [
    "K.set_floatx('float64')\n",
    "K.clear_session()\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{n_epochs}\")\n",
    "    \n",
    "    for step in range(1, n_steps + 1): # for the batches within an epoch\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train) # pick random id's to make a batch\n",
    "        \n",
    "        # make a prediciton for one batch (using the model as a function), and we compute the loss\n",
    "        with tf.GradientTape() as tape: \n",
    "            y_pred = model(X_batch) # predict the value\n",
    "            # mean_square_error() returns one loss per instance\n",
    "            # if you want to apply weights to each instance, you should do somthing different here \n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred)) # compute the mean over the batch \n",
    "            loss = tf.add_n([main_loss] + model.losses) # add all input element-wise \n",
    "        \n",
    "        # compute the gradients w.r.t trainable variables\n",
    "        gradients = tape.gradient(loss, model.trainable_variables) \n",
    "        # apply them to the optimizer to perform gradient descent step\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables)) \n",
    "        \n",
    "        ### If you add weight constraints to your model (e.g., by setting `kernel_constrain`\n",
    "        ### or 'bias_constraint' when creating a layer), update the training loop to apply\n",
    "        ### these constraints just after `apply_gradients()`\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        \n",
    "        # update the mean loss and the metrics (over the current epoch)\n",
    "        mean_loss(loss) # keras.metrics.Mean(name=\"loss\")\n",
    "        for metric in metrics: # [keras.metrics.MeanAbsoluteError(name=\"mae\")]\n",
    "            metric(y_batch, y_pred)\n",
    "        # display the status bar\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "        \n",
    "    # display the status bar again to make it look complete and to print a line feed    \n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "    # reset the states of the mean loss and the metrics\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is doing the same purpose but in fancier way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soohyeonkim/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d83a1a8d2ba4c53bc3e3f0a8eb891e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='All epochs', max=5.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soohyeonkim/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa2f18b36b54b07abc237c8e9b54439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1/5', max=362.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e2fe51f7044edaa93caa90afe1bb33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 2/5', max=362.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a494e8bc6ac14ceab4db7da612668b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 3/5', max=362.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca1e19f66224b61b0b42f6cb535490b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 4/5', max=362.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db5e4e5033bd435bba24403252739768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 5/5', max=362.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from tqdm import tnrange\n",
    "    from collections import OrderedDict\n",
    "    \n",
    "    with tnrange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "        for epoch in epochs:\n",
    "            with tnrange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
    "                for step in steps:\n",
    "                    X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        y_pred = model(X_batch)\n",
    "                        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                        loss = tf.add_n([main_loss] + model.losses)\n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                    for variable in model.variables:\n",
    "                        if variable.constraint is not None:\n",
    "                            variable.assign(variable.constraint(variable))                    \n",
    "                    status = OrderedDict()\n",
    "                    mean_loss(loss)\n",
    "                    status[\"loss\"] = mean_loss.result().numpy()\n",
    "                    for metric in metrics:\n",
    "                        metric(y_batch, y_pred)\n",
    "                        status[metric.name] = metric.result().numpy()\n",
    "                    steps.set_postfix(status)\n",
    "            for metric in [mean_loss] + metrics:\n",
    "                metric.reset_states()\n",
    "except ImportError as ex:\n",
    "    print(\"To run this cell, please install tqdm, ipywidgets and restart Jupyter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Functions\n",
    "\n",
    "In TensorFlow 1, graphs were unavoidable (as were the complexities that came with them) because they were a central part of TensorFlow's API. In TensorFlow 2, they are still there, but not as central, and they're much simpler to use! To show just how simple, let's start with a trivial function that computes the cube of its imput:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use `tf.function()` to convert this python function to `TensorFlow Function`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x7fee80f699d0>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube = tf.function(cube)\n",
    "tf_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This TF funciton can then be used exactly like the original Python function, and it will return the same result (but as tensors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, `tf.function()` analyzed the computations performed by the `cube()` function and generated an equivalent computation graph! As you can see, it was rather painless (we will see how this works shortly).\n",
    "\n",
    "Alternatively, we could have used `tf.function` as a decorator; this is actually more common:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x7fee80f5dd90>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The origianl Python function is still available via the TF function's `python_function` attribute, in case you ever need it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube.python_function(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TensorFlow optimizes the computation graph, pruning unused nodes, simplifying expressions (e.g., 1+2 would get replaced with 3), and more. Once the optimized graph is ready, the TF Function efficiently executes the operations in the graph, in the appropriate order (and in parallel when it can). As a result, a TF Function will usually run much faster than the original Python function, especially if it performs complex computations. Most of the time you will not really need to know more than that: when you want to boost a Python function, **just transform it into a TF Function**. That's all!\n",
    "> \n",
    "> Moreover, when you write a custom loss function, a custom metric, a custom layer, or any other custom function and you use it in a Keras model (as we did throughout this chapter), Keras automatically converts your function into a TF Function - no need to use `tf.function()`. So most of the time, all this magic is 100% transparent.\n",
    "\n",
    ">> You can tell Keras *`not`* to convert your Python functions to TF Functions by setting `dynamic=True` when creating a custom layer or a custom model. Alternatively, you can set `run_eagerly=True` when calling the model's `compile()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Functions and Concrete Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x7feec3ea7cd0>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
    "concrete_function.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function is tf_cube.get_concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Function Definitions and Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> tf_cube.graph\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "AttributeError                            Traceback (most recent call last)\n",
    "<ipython-input-472-331e82fb9f51> in <module>\n",
    "----> 1 tf_cube.graph\n",
    "\n",
    "AttributeError: 'Function' object has no attribute 'graph'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x7feec3ea7cd0>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'pow/y' type=Const>,\n",
       " <tf.Operation 'pow' type=Pow>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops = concrete_function.graph.get_operations()\n",
    "ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'x:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'pow/y:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op = ops[2]\n",
    "list(pow_op.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'pow:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'x' type=Placeholder>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph.get_operation_by_name('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Identity:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph.get_tensor_by_name('Identity:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"__inference_tf_cube_1062674\"\n",
       "input_arg {\n",
       "  name: \"x\"\n",
       "  type: DT_FLOAT\n",
       "}\n",
       "output_arg {\n",
       "  name: \"identity\"\n",
       "  type: DT_FLOAT\n",
       "}"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.function_def.signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How TF Functions Trace Python Functions to Extract Their Computation Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    print(\"print:\", x)\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: Tensor(\"x:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: 2\n",
      "print: 3\n",
      "print: Tensor(\"x:0\", shape=(1, 2), dtype=float32)\n",
      "print: Tensor(\"x:0\", shape=(2, 2), dtype=float32)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function tf_cube at 0x7feec5250ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "print: Tensor(\"x:0\", shape=(3, 2), dtype=float32)\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function tf_cube at 0x7feec5250ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(2)\n",
    "result = tf_cube(3)\n",
    "result = tf_cube(tf.constant([[1., 2.]])) # New shape: trace!\n",
    "result = tf_cube(tf.constant([[3., 4.], [5., 6.]])) # New shape: trace!\n",
    "result = tf_cube(tf.constant([[7., 8.], [9., 10.], [11., 12.]])) # no trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to specify a particular input signature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec([None, 28, 28], tf.float32)])\n",
    "def shrink(images):\n",
    "    print(\"Tracing\", images)\n",
    "    return images[:, ::2, ::2] # drop half the rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing Tensor(\"images:0\", shape=(None, 28, 28), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "img_batch_1 = tf.random.uniform(shape=[100, 28, 28])\n",
    "img_batch_2 = tf.random.uniform(shape=[50, 28, 28])\n",
    "preprocessed_images = shrink(img_batch_1) # Traces the function.\n",
    "preprocessed_images = shrink(img_batch_2) # Reuses the same concrete function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python inputs incompatible with input_signature:\n",
      "  inputs: (\n",
      "    tf.Tensor(\n",
      "[[[0.803156   0.49777734]\n",
      "  [0.37054038 0.9118674 ]]\n",
      "\n",
      " [[0.637642   0.18209696]\n",
      "  [0.63791955 0.27701473]]], shape=(2, 2, 2), dtype=float32))\n",
      "  input_signature: (\n",
      "    TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None))\n"
     ]
    }
   ],
   "source": [
    "img_batch_3 = tf.random.uniform(shape=[2, 2, 2])\n",
    "try:\n",
    "    preprocessed_images = shrink(img_batch_3)  # rejects unexpected types or shapes\n",
    "except ValueError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Autograph To Capture Control Flow\n",
    "\n",
    "#### `<AutoGraph and tracing>`\n",
    "<img src=\"https://github.com/soo-pecialist/Hands_on_ML_w_Scikit_Karas_and_TensorFlow/blob/master/images_used/figure12_4.png?raw=true\" alt=\"Figure 12-4\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"static\" `for` loop using `range()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in range(10):\n",
    "        x += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'add/y' type=Const>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'add_1/y' type=Const>,\n",
       " <tf.Operation 'add_1' type=AddV2>,\n",
       " <tf.Operation 'add_2/y' type=Const>,\n",
       " <tf.Operation 'add_2' type=AddV2>,\n",
       " <tf.Operation 'add_3/y' type=Const>,\n",
       " <tf.Operation 'add_3' type=AddV2>,\n",
       " <tf.Operation 'add_4/y' type=Const>,\n",
       " <tf.Operation 'add_4' type=AddV2>,\n",
       " <tf.Operation 'add_5/y' type=Const>,\n",
       " <tf.Operation 'add_5' type=AddV2>,\n",
       " <tf.Operation 'add_6/y' type=Const>,\n",
       " <tf.Operation 'add_6' type=AddV2>,\n",
       " <tf.Operation 'add_7/y' type=Const>,\n",
       " <tf.Operation 'add_7' type=AddV2>,\n",
       " <tf.Operation 'add_8/y' type=Const>,\n",
       " <tf.Operation 'add_8' type=AddV2>,\n",
       " <tf.Operation 'add_9/y' type=Const>,\n",
       " <tf.Operation 'add_9' type=AddV2>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"dynamic\" loop using `tf.while_loop()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    condition = lambda i, x: tf.less(i, 10)\n",
    "    body = lambda i, x: (tf.add(i, 1), tf.add(x, 1))\n",
    "    final_i, final_x = tf.while_loop(condition, body, [tf.constant(0), x])\n",
    "    return final_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"dynamic\" `for` loop using `tf.range()` (captured by autograph):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x = x + 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'range/start' type=Const>,\n",
       " <tf.Operation 'range/limit' type=Const>,\n",
       " <tf.Operation 'range/delta' type=Const>,\n",
       " <tf.Operation 'range' type=Range>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'floordiv' type=FloorDiv>,\n",
       " <tf.Operation 'mod' type=FloorMod>,\n",
       " <tf.Operation 'zeros_like' type=Const>,\n",
       " <tf.Operation 'NotEqual' type=NotEqual>,\n",
       " <tf.Operation 'Cast' type=Cast>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'zeros_like_1' type=Const>,\n",
       " <tf.Operation 'Maximum' type=Maximum>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(0)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Variables and Other Resources in TF Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(counter, c=1):\n",
    "    return counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment(counter)\n",
    "increment(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"counter\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def = increment.get_concrete_function(counter).function_def\n",
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(c=1):\n",
    "    return counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment()\n",
    "increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"assignaddvariableop_resource\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def = increment.get_concrete_function().function_def\n",
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.counter = tf.Variable(0)\n",
    "\n",
    "    @tf.function\n",
    "    def increment(self, c=1):\n",
    "        return self.counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter()\n",
    "c.increment()\n",
    "c.increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def tf__add_10(x):\\n    do_return = False\\n    retval_ = ag__.UndefinedReturnValue()\\n    with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\\n\\n        def get_state():\\n            return (x,)\\n\\n        def set_state(loop_vars):\\n            nonlocal x\\n            (x,) = loop_vars\\n\\n        def loop_body(itr):\\n            nonlocal x\\n            i = itr\\n            x += 1\\n        ag__.for_stmt(ag__.converted_call(tf.range, (10,), None, fscope), None, loop_body, get_state, set_state, ('x',), {})\\n        try:\\n            do_return = True\\n            retval_ = fscope.mark_return_value(x)\\n        except:\\n            do_return = False\\n            raise\\n    (do_return,)\\n    return ag__.retval(retval_)\\n\""
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x += 1\n",
    "    return x\n",
    "\n",
    "tf.autograph.to_code(add_10.python_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_tf_code(func):\n",
    "    from IPython.display import display, Markdown\n",
    "    if hasattr(func, \"python_function\"):\n",
    "        func = func.python_function\n",
    "    code = tf.autograph.to_code(func)\n",
    "    display(Markdown('```python\\n{}\\n```'.format(code)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def tf__add_10(x):\n",
       "    do_return = False\n",
       "    retval_ = ag__.UndefinedReturnValue()\n",
       "    with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
       "\n",
       "        def get_state():\n",
       "            return (x,)\n",
       "\n",
       "        def set_state(loop_vars):\n",
       "            nonlocal x\n",
       "            (x,) = loop_vars\n",
       "\n",
       "        def loop_body(itr):\n",
       "            nonlocal x\n",
       "            i = itr\n",
       "            x += 1\n",
       "        ag__.for_stmt(ag__.converted_call(tf.range, (10,), None, fscope), None, loop_body, get_state, set_state, ('x',), {})\n",
       "        try:\n",
       "            do_return = True\n",
       "            retval_ = fscope.mark_return_value(x)\n",
       "        except:\n",
       "            do_return = False\n",
       "            raise\n",
       "    (do_return,)\n",
       "    return ag__.retval(retval_)\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_tf_code(add_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TF Functions with tf.keras (or Not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, tf.keras will automatically convert your custom code into TF Functions, no need to use\n",
    "`tf.function()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss function\n",
    "def my_mse(y_true, y_pred):\n",
    "    print(\"Tracing loss my_mse()\")\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true)) # make sure to use tf.reduce_mean, not np.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric function\n",
    "def my_mae(y_true, y_pred):\n",
    "    print(\"Tracing metric my_mae()\")\n",
    "    return tf.reduce_mean(tf.abs(y_pred - y_true)) # make sure to use tf.reduce_mean, not np.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer\n",
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[1], self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.biases = self.add_weight(name='bias', \n",
    "                                      shape=(self.units,),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, X):\n",
    "        print(\"Tracing MyDense.call()\")\n",
    "        return self.activation(X @ self.kernel + self.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model\n",
    "class MyModel(keras.models.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = MyDense(30, activation=\"relu\")\n",
    "        self.hidden2 = MyDense(30, activation=\"relu\")\n",
    "        self.output_ = MyDense(1)\n",
    "\n",
    "    def call(self, input):\n",
    "        print(\"Tracing MyModel.call()\")\n",
    "        hidden1 = self.hidden1(input)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input, hidden2])\n",
    "        output = self.output_(concat)\n",
    "        return output\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "306/363 [========================>.....] - ETA: 0s - loss: 1.5177 - my_mae: 0.8509Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3579 - my_mae: 0.7967 - val_loss: 0.4520 - val_my_mae: 0.4797\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4407 - my_mae: 0.4780 - val_loss: 1.0628 - val_my_mae: 0.4744\n",
      "162/162 - 0s - loss: 0.4185 - my_mae: 0.4661\n",
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_dense (MyDense)           multiple                  270       \n",
      "_________________________________________________________________\n",
      "my_dense_1 (MyDense)         multiple                  930       \n",
      "_________________________________________________________________\n",
      "my_dense_2 (MyDense)         multiple                  39        \n",
      "=================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can turn this off by creating the model with `dynamic=True` (or calling `super().__init__(dynamic=True, \n",
    "**kwargs)` in the model's constructor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not the custom code will be called at each iteration. Let's fit, validate and evaluate with tiny datasets to avoid getting too much output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.5655248165130615, 2.062637794448646]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled[:64], y_train[:64], epochs=1,\n",
    "          validation_data=(X_valid_scaled[:64], y_valid[:64]), verbose=0)\n",
    "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can compile a model with `run_eagerly=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "2/2 - 0s - loss: 5.5356 - my_mae: 2.0609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.535620450973511, 2.060903796271556]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled[:64], y_train[:64], epochs=1,\n",
    "          validation_data=(X_valid_scaled[:64], y_valid[:64]), verbose=0)\n",
    "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining custom optimizers is not very common, but in case you are one of the happy few who gets to write one, here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMomentumOptimizer(keras.optimizers.Optimizer):\n",
    "    def __init__(self, learning_rate=0.001, momentum=0.9, name=\"MyMomentumOptimizer\", **kwargs):\n",
    "        \"\"\"Call super().__init__() and use _set_hyper() to store hyperparameters\"\"\"\n",
    "        super().__init__(name, **kwargs)\n",
    "        self._set_hyper(\"learning_rate\", kwargs.get(\"lr\", learning_rate)) # handle lr=learning_rate\n",
    "        self._set_hyper(\"decay\", self._initial_decay) # \n",
    "        self._set_hyper(\"momentum\", momentum)\n",
    "    \n",
    "    def _create_slots(self, var_list):\n",
    "        \"\"\"For each model variable, create the optimizer variable associated with it.\n",
    "        TensorFlow calls these optimizer variables \"slots\".\n",
    "        For momentum optimization, we need one momentum slot per model variable.\n",
    "        \"\"\"\n",
    "        for var in var_list:\n",
    "            self.add_slot(var, \"momentum\")\n",
    "\n",
    "    @tf.function\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        \"\"\"Update the slots and perform one optimization step for one model variable\n",
    "        \"\"\"\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype) # handle learning rate decay\n",
    "        momentum_var = self.get_slot(var, \"momentum\")\n",
    "        momentum_hyper = self._get_hyper(\"momentum\", var_dtype)\n",
    "        momentum_var.assign(momentum_var * momentum_hyper - (1. - momentum_hyper)* grad)\n",
    "        var.assign_add(momentum_var * lr_t)\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n",
    "            \"decay\": self._serialize_hyperparameter(\"decay\"),\n",
    "            \"momentum\": self._serialize_hyperparameter(\"momentum\"),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 638us/step - loss: 3.6893\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 628us/step - loss: 1.2082\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 613us/step - loss: 0.7380\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 619us/step - loss: 0.6287\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 614us/step - loss: 0.5982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feed12ef990>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([keras.layers.Dense(1, input_shape=[8])])\n",
    "model.compile(loss=\"mse\", optimizer=MyMomentumOptimizer())\n",
    "model.fit(X_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.39463088,  0.60898352,  0.29419561, -1.55363455, -0.53030964],\n",
       "       [-0.82962224,  0.38114553,  0.01272966,  0.8396774 ,  1.503092  ],\n",
       "       [-1.13028289, -0.95660853, -0.39176695,  0.80655385, -1.49892278],\n",
       "       [ 1.86741899,  0.99893448,  0.07057056,  1.27461511, -0.20493672]])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.random.randn(4, 5)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.39463088,  0.60898352,  0.29419561, -1.55363455, -0.53030964])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.31507918923852785"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0].mean(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31507919],\n",
       "       [ 0.38140447],\n",
       "       [-0.63420546],\n",
       "       [ 0.80132048]])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.mean(axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "# 12. Implement a custom layer that performs _Layer Normalization_\n",
    "_We will use this type of layer in Chapter 15 when using Recurrent Neural Networks._\n",
    "> Layer Normalization:\n",
    ">\n",
    "> Normalize the activations of the previous layer for each given example in a batch independently, rather than across a batch like Batch Normalization. i.e. applies a transformation that maintains the mean activation within each example close to 0 and the activation standard deviation close to 1.\n",
    "\n",
    "\n",
    "### a.\n",
    "_Exercise: The `build()` method should define two trainable weights *α* and *β*, both of shape `input_shape[-1:]` and data type `tf.float32`. *α* should be initialized with 1s, and *β* with 0s._\n",
    "\n",
    "Solution: see below.\n",
    "\n",
    "### b.\n",
    "_Exercise: The `call()` method should compute the mean_ μ _and standard deviation_ σ _of each instance's features. For this, you can use `tf.nn.moments(inputs, axes=-1, keepdims=True)`, which returns the mean μ and the variance σ<sup>2</sup> of all instances (compute the square root of the variance to get the standard deviation). Then the function should compute and return *α*⊗(*X* - μ)/(σ + ε) + *β*, where ⊗ represents itemwise multiplication (`*`) and ε is a smoothing term (small constant to avoid division by zero, e.g., 0.001)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(keras.layers.Layer):\n",
    "    def __init__(self, eps=0.001, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "    \n",
    "    def build(self, batch_input_shape):\n",
    "        self.alpha = self.add_weight(\n",
    "            name=\"alpha\", shape=batch_input_shape[-1:],\n",
    "            initializer=\"ones\")\n",
    "        self.beta = self.add_weight(\n",
    "            name=\"beta\", shape=batch_input_shape[-1:],\n",
    "            initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "    \n",
    "    def call(self, X):\n",
    "        mean, variance = tf.nn.moments(X, axes=-1, keepdims=True)\n",
    "        return self.alpha * (X-mean) / (tf.sqrt(variance + self.eps)) + self.beta\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"eps\": self.eps}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that making _ε_ a hyperparameter (`eps`) was not compulsory. Also note that it's preferable to compute `tf.sqrt(variance + self.eps)` rather than `tf.sqrt(variance) + self.eps`. Indeed, the derivative of sqrt(z) is undefined when z=0, so training will bomb whenever the variance vector has at least one component equal to 0. Adding _ε_ within the square root guarantees that this will never happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\n",
    "_Exercise: Ensure that your custom layer produces the same (or very nearly the same) output as the `keras.layers.LayerNormalization` layer._\n",
    "\n",
    "Let's create one instance of each class, apply them to some data (e.g., the training set), and ensure that the difference is negligeable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=5.6045884e-08>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "X = X_train.astype(np.float32)\n",
    "\n",
    "custom_layer_norm = LayerNormalization()\n",
    "keras_layer_norm = keras.layers.LayerNormalization()\n",
    "\n",
    "tf.reduce_mean(keras.losses.mean_absolute_error(\n",
    "    keras_layer_norm(X), custom_layer_norm(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yep, that's close enough. To be extra sure, let's make alpha and beta completely random and compare again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.9115708e-08>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_alpha = np.random.rand(X.shape[-1])\n",
    "random_beta = np.random.rand(X.shape[-1])\n",
    "\n",
    "custom_layer_norm.set_weights([random_alpha, random_beta])\n",
    "keras_layer_norm.set_weights([random_alpha, random_beta])\n",
    "\n",
    "tf.reduce_mean(keras.losses.mean_absolute_error(\n",
    "    keras_layer_norm(X), custom_layer_norm(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still a negligeable difference! Our custom layer works fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Train a model using a custom training loop to tackle the Fashion MNIST dataset\n",
    "_The Fashion MNIST dataset was introduced in Chapter 10._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\n",
    "_Exercise: Display the epoch, iteration, mean training loss, and mean accuracy over each epoch (updated at each iteration), as well as the validation loss and accuracy at the end of each epoch._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full.astype(np.float32) / 255.\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test.astype(np.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation = \"relu\"),\n",
    "    keras.layers.Dense(10, activation = \"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
    "loss_fn = keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> tqdm - postfix: Specify additional stats to display at the end of the bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soohyeonkim/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6a48c173d6413db3e9946babef5849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='All epochs', max=5.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soohyeonkim/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85aaa9351ca41238677f71b2083188a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1/5', max=1718.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3601d6c2174cb1992e59f6cb4940be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 2/5', max=1718.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455523a5e5e542f79c716fba76d81b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 3/5', max=1718.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999b128dbd4a48f1afcfcb7dd82ee636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 4/5', max=1718.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc07e88daa4a4604adf24a401334fd01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 5/5', max=1718.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tnrange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        #### {begin} EPOCH\n",
    "        with tnrange(1, n_steps+1, desc=f\"Epoch {epoch}/{n_epochs}\") as steps:\n",
    "            for step in steps:\n",
    "                #### {begin} BATCH - training\n",
    "                X_batch, y_batch = random_batch(X_train, y_train)\n",
    "                with tf.GradientTape() as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))\n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status[\"loss\"] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "                steps.set_postfix(status)\n",
    "                #### {end} BATCH - training\n",
    "            y_pred = model(X_valid)\n",
    "            status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
    "            status[\"val_accuracy\"]  = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
    "                tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "            steps.set_postfix(status)\n",
    "        ### {end} EPOCH\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8552"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "np.mean(np.argmax(model(X_test), axis=1) == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "_Exercise: Try using a different optimizer with a different learning rate for the upper layers and the lower layers._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_layers = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "])\n",
    "\n",
    "upper_layers = keras.models.Sequential([\n",
    "    keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    lower_layers, upper_layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_optimizer = keras.optimizers.SGD(lr=1e-4)\n",
    "upper_optimizer = keras.optimizers.Nadam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "loss_fn = keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soohyeonkim/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c90fe6bece64b1690725c4a36eb6574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='All epochs', max=5.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soohyeonkim/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77250c0691c9462ebe9d25936e157ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1/5', max=1718.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6257793cc1d04f4fa1f0781025d77baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 2/5', max=1718.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e835f36ca5433cbd1b49297e3dc412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 3/5', max=1718.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6912e5bd886d4a1290654ec88eaf0f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 4/5', max=1718.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e898d5c454401cad0c232abfe031dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 5/5', max=1718.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tnrange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        with tnrange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train, y_train)\n",
    "                with tf.GradientTape(persistent=True) as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "                ## different here\n",
    "                for layers, optimizer in ((lower_layers, lower_optimizer),\n",
    "                                          (upper_layers, upper_optimizer)):\n",
    "                    gradients = tape.gradient(loss, layers.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, layers.trainable_variables))\n",
    "                del tape\n",
    "                ###################\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))                    \n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status[\"loss\"] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "                steps.set_postfix(status)\n",
    "            y_pred = model(X_valid)\n",
    "            status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
    "            status[\"val_accuracy\"] = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
    "                tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "            steps.set_postfix(status)\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.809"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "np.mean(np.argmax(model(X_test), axis=1) == y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
